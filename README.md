# cs231n
## Assignment 1
### Q1: k最近邻分类器
Notebook knn.ipynb将引导您实现k最近邻分类器。

### Q2: 训练支持向量机
Notebook svm.ipynb将引导您实现支持向量机分类器。

### Q3: 实现Softmax分类器
Notebook softmax.ipynb将引导您实现Softmax分类器。

### Q4: 两层神经网络
Notebook two_layer_net.ipynb将引导您实现两层神经网络分类器。

### Q5: 更高级的表示：图像特征
Notebook features.ipynb将研究使用高级表示相对于使用原始像素值所获得的改进。

## Assignment 2
### Q1: 多层全连接神经网络
Notebook FullyConnectedNets.ipynb将引导您实现任意深度的全连接网络。为了优化这些模型，您将实现几种流行的更新规则。

### Q2: 批归一化
Notebook BatchNormalization.ipynb中，您将实现批归一化，并将其用于训练深度全连接网络。

### Q3: Dropout
Notebook Dropout.ipynb将帮助您实现dropout并探索其对模型泛化性能的影响。

### Q4: 卷积神经网络
Notebook ConvolutionalNetworks.ipynb中，您将实现几个在卷积网络中常用的新层。

### Q5: CIFAR-10上的PyTorch
在这部分中，您将使用PyTorch，一个流行而强大的深度学习框架。
打开PyTorch.ipynb。在那里，您将学习该框架的工作原理，并最终在CIFAR-10上训练自己设计的卷积网络，以获得最佳性能。

## Assignment 3
### Q1: 网络可视化：显著性图、类别可视化和欺骗图像
Notebook Network_Visualization.ipynb将介绍预训练的SqueezeNet模型，计算图像的梯度，并使用它们生成显著性图和欺骗图像。

### Q2: 使用Vanilla RNN进行图像字幕生成
Notebook RNN_Captioning.ipynb将引导您实现基本的循环神经网络，并将其应用于COCO数据集的图像字幕生成任务。

### Q3: 使用Transformer进行图像字幕生成
Notebook Transformer_Captioning.ipynb将引导您实现Transformer模型，并将其应用于COCO数据集的图像字幕生成任务。

### Q4: 生成对抗网络
Notebook Generative_Adversarial_Networks.ipynb中，您将学习如何生成与训练数据集匹配的图像，并使用这些模型在大量未标记数据和少量标记数据上改进分类器的性能。

### Q5: 自监督学习用于图像分类
Notebook Self_Supervised_Learning.ipynb中，您将学习如何利用自监督预训练来在图像分类任务上获得更好的性能。

### 额外加分项：使用LSTM进行图像字幕生成
Notebook LSTM_Captioning.ipynb将引导您实现长短时记忆（LSTM）循环神经网络，并将其应用于COCO数据集的图像字幕生成任务。

